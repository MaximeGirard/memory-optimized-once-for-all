# TRAINING & GENERAL
args:
  # For supernet training only
  path: "models/CompOFA/"
  # For teacher model training and evaluation
  teacher_path: "models/CompOFA/teacher/"
  # For OFA supernet evaluation and search
  checkpoint: "models/CompOFA/model_best_compofa_simple_elastic.pth.tar"
  # Options are: "OFA", "CompOFA", "MOOFA_V1", "MOOFA_V2", "MOOFA_V3"
  model: "CompOFA"
  # Options are: "imagenette", "imagenet"
  dataset: "imagenet"
  # General training parameters
  base_batch_size: 64
  base_stage_width: "proxyless"
  bn_eps: 1.0e-5
  bn_momentum: 0.1
  continuous_size: true
  distort_color: "tf"
  dropout: 0.1
  dy_conv_scaling_mode: 1
  fp16_allreduce: false
  independent_distributed_sampling: false
  kd_ratio: 1.0
  kd_type: "ce"
  label_smoothing: 0.1
  lr_schedule_type: "cosine"
  manual_seed: 0
  model_init: "he_fout"
  momentum: 0.9
  n_worker: 12
  no_decay_keys: "bn#bias"
  no_nesterov: false
  not_sync_distributed_image_size: false
  opt_type: "sgd"
  print_frequency: 10
  resize_scale: 0.08
  valid_size: 100
  validation_frequency: 1
  weight_decay: 3.0e-5

# TRAINING PHASES
tasks: ["kernel", "depth", "expand"]
tasks_phases:
  kernel: 1
  depth: 2
  expand: 2

# TASKS, set the number of epochs, learning rate, warmup epochs,
# warmup learning rate and dynamic batch size for each task
args_per_task:
  teacher:
    n_epochs: 180
    base_lr: 3.0e-2
    warmup_epochs: 0 
    warmup_lr: 3.0e-3
    dynamic_batch_size: 1
  kernel_1:
    n_epochs: 120
    base_lr: 3.0e-3
    warmup_epochs: 5
    warmup_lr: 3.0e-3
    dynamic_batch_size: 1
  depth_1:
    n_epochs: 25
    base_lr: 2.5e-4
    warmup_epochs: 0
    warmup_lr: 2.5e-3
    dynamic_batch_size: 2
  depth_2:
    n_epochs: 120
    base_lr: 7.5e-4
    warmup_epochs: 5
    warmup_lr: 7.5e-5
    dynamic_batch_size: 2
  expand_1:
    n_epochs: 25
    base_lr: 2.5e-4
    warmup_epochs: 0
    warmup_lr: 2.5e-5
    dynamic_batch_size: 4
  expand_2:
    n_epochs: 120
    base_lr: 2.5e-4
    warmup_epochs: 5
    warmup_lr: 7.5e-5
    dynamic_batch_size: 4


# EVAL
subnet_config:
  random_sample: false
  ks: [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]
  e: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
  d: [4, 4, 4, 4, 4]
  image_size: 224
  res_dir: "results/CompOFA/"
  name: "reference_subnet"
  draw_graphs: true

# SEARCH
search_config:
  # Search will be performed for N constraints linearly
  # distributed on the interval [min_constraint, max_constraint]
  N_constraint: 10
  max_constraint: 300000
  min_constraint: 800000
  res_dir: "searches/CompOFA/"
  acc_dataset_path: "acc_predictor_datasets/adapted/CompOFA/dataset.pkl"
  acc_predictor_checkpoint: "acc_predictor_checkpoints/CompOFA_acc.pth.tar"

# LOGGING
wandb:
  use_wandb: true
  project_name: "memory-optimized-once-for-all"  
